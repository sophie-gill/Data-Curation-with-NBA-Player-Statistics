# -*- coding: utf-8 -*-
"""Group Project Web-Scraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S22toXQSZqvldCmKe0L4Chu-YpAxT944

# Rookies to All-Stars: A Statistical Analysis of NBA Careers

I310D Final Project (Spring 2024)

Professor Abhijit Mishra

Data Monsters (Group): Sunidhi Ayyagari, Sarah Ding, Sophie Gill, Sabrina Lu

# Overall Project Description

This project aims to create a machine learning model that predicts NBA career retention based on a playerâ€™s rookie year performance. Our product is important because it can help recruiters/team managers predict star players (on/off their team) before their prime. As the average NBA player's salary is $10.8 million, it is important for teams to diligently decide who to invest their funds in (Fisher, 2023). For audiences, many participate in betting/predicting the outcomes of NBA games. Consequently, a machine learning model using predictive statistics of players would better inform betting decisions.

Citation:

Fisher, E. (2023, October 24). NBA sees $100m annual player salaries in its future. Front Office Sports. https://frontofficesports.com/nba-sees-100m-annual-player-salaries-in-its-future/

# Table of Contents

This notebook will capture our the following aspects of our project:

*   Data Preparation
  *   Extract Rookie Data
  *   Transform Rookie Data
  *   Extract Professional Data
  *   Label Rookie Data (Active/Inactive)
  *   Load to CSV
*   Exploratory Analysis of Data
  *   Heat Map of Features
*   Train Model (Logistic Regression)
*   Model Evaluation (Classification Reports)
  *   Cross Validation  
  *   K-Fold Cross Validation
*   Model Error Analysis
  *   Test Cases

#Data Preparation

## (1) Extract and Transform Rookie Data
"""

# Load all necessary packages for rest of analysis
from bs4 import BeautifulSoup
import pandas as pd
import pandas
import requests
import scipy

"""The following code chunk makes a request to the NBA statistic webpage (rookies) that I will be collecting information from and uses BeautifulSoup to parse it."""

# connect to data source website
opened_webpage = requests.get("https://www.basketball-reference.com/leagues/NBA_2018_rookies.html")
print("Webpage opened successfully...")

# Initialize a BeautifulSoup object to parse the webpage content
bs = BeautifulSoup(opened_webpage.content, "html.parser")
print("Webpage loaded and parsed successfully...")

"""The following code sections will extract the rookie player data information from the webpage and remove the empty rows scraped."""

#scraping raw data with BS
# Define an empty list where the data will be kept
raw_data = []

# Find the table on the webpage
table = bs.find("table")

if table:
    # Iterate through rows in the table
    for i, row in enumerate(table.find_all('tr')):
        # Extract data from each cell in row
        cells = row.find_all('td')
        row_data = [cell.text.strip() for cell in cells]
        raw_data.append(row_data)

    print(raw_data)

len(raw_data) #includes empty arrays

#removing empty arrays from BS scraping
cleaned_data = raw_data

for x in cleaned_data:
  if x == []:
    cleaned_data.remove(x)

len(cleaned_data) #126, the total number of rookie players on the website

"""The following code sections add the rank value of the players since it was not able to be scraped by BS. Players were scraped in rank order, so the rank value is assigned in numeric order."""

#add rank value to each row (since was not scraped with BS)
rank = 1

for x in cleaned_data:
  x.insert(0, rank)
  rank = rank+1

print(cleaned_data)

"""The following code sections selects the category headers to load all the information into a rookie data dataframe."""

#determine the length of each row/number of categories per row
#needed to index category headers

row = cleaned_data[0]
num_categories = len(row)

num_categories

#scraping row category headers

# Define an empty list where the data will be kept
raw_data = []
raw_headers = []

# list objects to store row data
header_data = []
for row in table.find_all('tr'):
  #scrap header data
  header = row.find_all('th')
  if len(header) > 0:
    for i in range(len(header)):
      header_data.append(header[i].text.strip())
    raw_headers.append(header_data)

#print(raw_headers)

#get the headers for one row of data (first 4 are other headings in table, after it repeats)
category_labels = raw_headers[0][4:(4+num_categories)]

print(category_labels)

#convert scraped data into dataframe

rookie_df = pandas.DataFrame(cleaned_data, columns=category_labels)
rookie_df

"""## (2) Extract and Transform Professional Data (Names)

The following code chunk makes a request to the NBA statistic webpage (professionals) that I will be collecting information from and uses BeautifulSoup to parse it.
"""

opened_webpage = requests.get("https://www.basketball-reference.com/leagues/NBA_2023_per_game.html")
print("Webpage opened successfully...")

# Initialize a BeautifulSoup object to parse the webpage content
bs2 = BeautifulSoup(opened_webpage.content, "html.parser")
print("Webpage loaded and parsed successfully...")

"""The following code sections will extract the professional player data information from the webpage and remove the empty rows scraped."""

#scraping row data with BS
# Define an empty list where the data will be kept
raw_data2 = []

# Find the table on the webpage
table = bs2.find("table")

if table:
    # Iterate through rows in the table
    for i, row in enumerate(table.find_all('tr')):
        # Extract data from each cell in row
        cells = row.find_all('td')
        row_data = [cell.text.strip() for cell in cells]
        raw_data2.append(row_data)

    print(raw_data2)

len(raw_data2) #includes empty arrays

#removing empty arrays
cleaned_data = raw_data2

for x in cleaned_data:
  if x == []:
    cleaned_data.remove(x)

len(cleaned_data) #679, total rows in professional player table

"""The following code chunk puts all the scraped professional names into a list."""

#get professional names
professional_player_names = []
for x in cleaned_data:
  professional_player_names.append(x[0])

professional_player_names

len(professional_player_names)

"""## (3) Label Active Status for Rookie Data"""

#select rookie names
rookie_names = rookie_df['Player']

rookie_names

"""This following code chunk compares the name list of professional players to the selected list of rookie players. The code parses through the rookie name list, and the 'in' function is used to see if that name is in the professional name list. If the name is in the list, then a 1 (for active status) is appended to the list of active statuses. Otherwise, a 0 is appended (for inactive status)."""

#create array of active status per player
# 1 = active; 0 = inactive
active_status = []

for name in rookie_names:
  #check if rookie name is in current professional player name list
  if name in professional_player_names:
    active_status.append(1)
  else:
    active_status.append(0)

len(active_status)

#add active status as a column in rookie_df
rookie_df = rookie_df.assign(Active=active_status)

rookie_df

active = rookie_df['Player'][rookie_df['Active']==1]
num_active= len(active)

print(f'There are {num_active} active players remaining from the {len(rookie_df)} players of the 2017-2018 NBA Rookie Class in the 2022-2023 NBA season.')

"""## (4) Load Data CSV"""

#select columns to use to train the classifier
processed_data = rookie_df[["Active", "Rk", "Player", "Age", "Yrs", "G", "MP", "PTS"]] #explain each of the selected columns

processed_data.to_csv('processed_NBA_rookie_data.csv')

"""We did not check for missing data since the number of players matched the number of players on the website. We did not check for duplicates for similar reasons.

# Exploratory Analysis (Heat Map)

We made a heat map of all the depicting the correlations between the seven features of the rookie data we are using for training the ML model.

The heat map depicts high correlation between features, which reveals the collinearity between selected features. ML models are best trained on non-collienar features (features that provide different information about the dataset), so this highlights the oppurtunity for future work to include different features such as socioeconomic factors (like race).
"""

import seaborn as sns
import matplotlib.pyplot as plt


plt.figure(figsize=(12,10))
cor = X.corr()
sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)
plt.show()

"""# Train Data to Classifier (Logistic Regression)

Load the saved cleaned data as a dataframe
"""

clean_rookie_df = pd.read_csv('processed_NBA_rookie_data.csv')

"""Features to train the ML model are selected to train the Logistic Regression for an 80%/20% train/test split."""

features = ["Age", "Yrs", "G", "MP_Total", "MP_Per_Game", "PTS_Total", "PTS_Per_Game"]
X = clean_rookie_df[features]
y = clean_rookie_df['Active']


from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.20, random_state=1)

model = LogisticRegression()
model.fit(X_train, y_train)
predictions = model.predict(X_test)

model.score(X_test, y_test)
print(classification_report(y_test, predictions))

"""To make our classification more accurate, we used KFold classification (5 fold)."""

from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

features = ["Age", "Yrs", "G", "MP_Total", "MP_Per_Game", "PTS_Total", "PTS_Per_Game"]
X = clean_rookie_df[features]
y = clean_rookie_df['Active']

# Perform k-fold cross-validation
scores = cross_val_score(model, X, y, cv=5)

print("Cross-Validation Scores:", scores)
print("Average Cross-Validation Score:", scores.mean())

# For individual scores
for fold, (train_idx, test_idx) in enumerate(StratifiedKFold(n_splits=5, shuffle=True, random_state=1).split(X, y)):
    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

    model.fit(X_train, y_train)
    predictions = model.predict(X_test)

    print(f"\nClassification Report for Fold {fold+1}:")
    print(classification_report(y_test, predictions))

"""# Error Analysis

To understand the errors of our ML model, we created 5 different edge cases to test how our ML model would perform.

Conditions of 5 edge cases:

1.   Active Rookie [active]
2.   Age 0 [inactive]
3.   0 Games Played [inactive]
4.   0 Points [inactive]
5.   0 Years Played [inactive]

###Edge Cases
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
import statistics


edge_cases = [
    {'Age': 20, 'Yrs': 7, 'G': 20, 'MP_Total': 500, 'MP_Per_Game': 20, 'PTS_Total': 200, 'PTS_Per_Game': 10}, #Active Player
    {'Age': 0, 'Yrs': 1, 'G': 10, 'MP_Total': 500, 'MP_Per_Game': 20, 'PTS_Total': 200, 'PTS_Per_Game': 10},  # Age of 0
    {'Age': 25, 'Yrs': 1, 'G': 0, 'MP_Total': 0, 'MP_Per_Game': 0, 'PTS_Total': 0, 'PTS_Per_Game': 0},  # 0 Games Played
    {'Age': 25, 'Yrs': 1, 'G': 20, 'MP_Total': 200, 'MP_Per_Game': 20, 'PTS_Total': 0, 'PTS_Per_Game': 0},  # 0 Point
    {'Age': 20, 'Yrs': 0, 'G': 10, 'MP_Total': 500, 'MP_Per_Game': 20, 'PTS_Total': 200, 'PTS_Per_Game': 10},  # 0 Years played
]

y_actual = [1, 0, 0, 0, 0]
y_match = []

edge_case_df = pd.DataFrame(edge_cases, columns=["Age", "Yrs", "G", "MP_Total", "MP_Per_Game", "PTS_Total", "PTS_Per_Game"])
y_predicted = model.predict(edge_case_df)

for i in range(len(y_actual)):
  if y_actual[i] == y_predicted[i]:
    y_match.append(1)
  else:
    y_match.append(0)

avg_match = statistics.mean(y_match)

print(f"actual: {y_actual}")
print(f"predicted: {y_predicted}")
print(f"match: {y_match}")
print(f"match accuracy: {y_match}")
print(y_predicted)
print(y_match)
avg_match

"""Our model accurately predicts 4/5 of our edge cases. It incorrectly predicts the second case where the player of age 0 would have been an active player. This highlights that the collinearity of the training data likely makes it an inaccurate predictor for data outside of the training data we trained the model with. Additionally, this highlights the impacts of our small sample data. Consequently, for future work, to improve the prediction accuracy of our model, we would train our model on a larger data set and different features to improve our model to fulfill our actual goal: using rookie data to predict NBA player performance."""